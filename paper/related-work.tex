\section{Related Work}
\label{sec:related-work}

Sampling has a long history, with most applications focusing on
performance profiling and optimization.  Any sampling system must
define a trigger mechanism that signals when a sample is to be taken.
Typical triggers include periodic hardware timers/interrupts
\cite{Burrows:2000:EFV,Traub:200:EILPP,Whaley:337483}, periodic
software event counters (e.g., every $n$th function call)
\cite{Arnold:2000:ACCTS}, or both.  In most cases, the sampling
interval is strictly periodic; this may suffice when hunting for large
performance bottlenecks, but may systematically miss rare events.

The Digital Continuous Profiling Infrastructure
\cite{Anderson:1997:CPW} is unusual in choosing sampling intervals
randomly.  However, the random distribution is uniform, such as one
sample every 60K to 64K cycles.  Samples thus extracted are not
independent.  If one sample is taken, there is zero chance of taking
any sample in the next 1--59,999 cycles and zero chance of \emph{not}
taking exactly one sample in the next 60K--64K cycles.  We trigger
samples based on a geometric distribution, which correctly models the
interval between successful independent coin tosses.  The resulting data is a
statistically rigorous fair random sample, which in turn grants access
to a large domain of powerful statistical analyses.

Recent work in trace collection has focused on program understanding.
Techniques for capturing program traces confront challenges similar to
those we face here, such as minimizing performance overhead and
managing large quantities of captured data.  Dynamic analysis in
particular must encode, compress, or otherwise reduce an incoming
trace stream in real time, as the program runs
\cite{Demsky:RBEOOP:2002,ICSE01*221}.  It may be difficult to directly
adapt dynamic trace analysis techniques to a domain where the trace is
sampled and therefore incomplete.  

Our effort to understand and debug programs by selecting predicates is
partly inspired by Daikon \cite{ernst2001}.  Like Daikon, we begin
with fairly unstructured guesses and eliminate those that do not
appear to hold.  Daikon collects a complete trace of individual
program values; generation and testing of possible invariants occurs
off line.  This gives Daikon greater flexibility to consider a
larger family of candidate invariants than we have examined, as a
significant part of our predicate testing happens within the client
itself.  With a large enough user population, though, the myriad
invariants considered by Daikon could certainly be tested.

The DIDUCE project \cite{Hangal:DIDUCE:2002} also attempts to identify
program invariants.  Unlike Daikon, most processing does take place
within the client program.  As in our study, DIDUCE attempts to relate
changes in predicates to the manifestation of bugs.  However, DIDUCE
performs complete tracing and focuses on discrete state changes, such
as the first time a predicate transitioned from true to false.  Our
approach is more probabilistic: we wish to identify broad trends over
time that correlate predicate violations with increased likelihood of
failure.  

Software tomography as realized through the GAMMA system
\cite{PASTE'02*2} shares our goal of low-overhead distributed
monitoring of deployed code.  Applications to date have focused on
code coverage and traditional performance monitoring tasks, whereas
our primary interest is bug isolation.  
%Our strategy uses
%randomization within a single instrumented binary, while GAMMA
%emphasizes choices in initial probe placement and iterative refinement
%over time.  Our earlier discussion of statically selective sampling
%(Section~\ref{sec:ccured:single}) suggests that these two
%considerations are complementary.

%% LocalWords: DIDUCE
